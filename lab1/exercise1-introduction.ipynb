{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4HI2mpwlrcn"
   },
   "source": [
    "# Lab 1: Experiment Tracking\n",
    "## Exercise 1: Introduction to CIFAR-10\n",
    "\n",
    "The following code demonstrates training a simple [Convolutional Neural Network](https://en.wikipedia.org/wiki/Convolutional_neural_network) (CNN) to classify [CIFAR images](https://www.cs.toronto.edu/~kriz/cifar.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install python packages\n",
    "!pip install -q tensorflow matplotlib\n",
    "\n",
    "# import to use them\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRFxccghyMVo"
   },
   "source": [
    "### Download and Prepare the CIFAR-10 Dataset\n",
    "\n",
    "The CIFAR-10 dataset contains 60,000 color images in 10 classes, with 6,000 images in each class. The dataset is divided into 50,000 training images and 10,000 testing images. We only use the training images because that's more than enough for our purposes.\n",
    "\n",
    "For this workshop, we choose four classes and create a subset of the dataset. Feel free to change which classes are used!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JWoEqyMuXFF4"
   },
   "outputs": [],
   "source": [
    "# download the dataset\n",
    "(images, labels), _ = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# there are 10 classes of images\n",
    "all_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# choose four classes (feel free to change this!)\n",
    "class_names = [\"bird\", \"cat\", \"deer\", \"dog\"]\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "# only keep images of these classes\n",
    "class_indexes = [all_classes.index(c) for c in class_names]\n",
    "to_keep = np.array([l in class_indexes for l in labels])\n",
    "images = images[to_keep]\n",
    "labels = labels[to_keep]\n",
    "\n",
    "# change indexes from 10 to 2 classes\n",
    "labels = np.array([class_indexes.index(l) for l in labels])\n",
    "\n",
    "# normalize pixels between 0 and 1\n",
    "images = images / 255.0\n",
    "\n",
    "# split into train and test set\n",
    "split = round(len(images) * 0.8)\n",
    "train_images = images[:split]\n",
    "train_labels = labels[:split]\n",
    "test_images = images[split:]\n",
    "test_labels = labels[split:]\n",
    "print(\"Number of train images:\", len(train_images))\n",
    "print(\"Number of test images:\", len(test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wArwCTJJlUa"
   },
   "source": [
    "### Verify the data\n",
    "\n",
    "To verify that the dataset looks correct, let's plot the first 25 images from the training set and display the class name below each image:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K3PAELE2eSU9"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i])\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oewp-wYg31t9"
   },
   "source": [
    "### Create convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hQvqXpNyN3x"
   },
   "source": [
    "The code below define the convolutional base using a common pattern: a stack of [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) and [MaxPooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) layers.\n",
    "\n",
    "As input, a CNN takes tensors of shape (image_height, image_width, color_channels), ignoring the batch size. If you are new to these dimensions, color_channels refers to (R,G,B). In this example, you will configure your CNN to process inputs of shape (32, 32, 3), which is the format of CIFAR images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9YmGQBQPrdn"
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.Input(shape=(32, 32, 3)))\n",
    "\n",
    "model.add(layers.Conv2D(4, (3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(8, (3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(8, (3, 3), activation=\"relu\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_v8sVOtG37bT"
   },
   "source": [
    "### Add Dense layers on top\n",
    "\n",
    "To complete the model, you will feed the last output tensor from the convolutional base (of shape (4, 4, 8)) into one or more Dense layers to perform classification. Dense layers take vectors as input (which are 1D), while the current output is a 3D tensor. First, you will flatten the 3D output to 1D,  then add one or more Dense layers on top. We have 4 output classes, so you use a final Dense layer with 4 outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRs95d6LUVEi"
   },
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(16, activation=\"relu\"))\n",
    "model.add(layers.Dense(4, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipGiQMcR4Gtq"
   },
   "source": [
    "Here's the complete architecture of your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Yu_m-TZUWGX"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3odqfHP4M67"
   },
   "source": [
    "### Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MdDzI75PUXrG"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10,\n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKgyC5K_4O0d"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtyDF0MKUcM7"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.title(\"Training\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print(f\"Test accuracy: {100 * test_acc:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show predictions\n",
    "plt.figure(figsize=(7,7))\n",
    "predictions = model.predict(train_images[:25])\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i])\n",
    "    predict = np.argmax(predictions[i])\n",
    "    actual = train_labels[i]\n",
    "    if predict == actual:\n",
    "        plt.xlabel(f\"{class_names[actual]}\")\n",
    "    else: # wrong prediction\n",
    "        plt.xlabel(f\"WRONG {class_names[actual]}\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cnn.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
